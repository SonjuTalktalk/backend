"""
ì†ì£¼í†¡í†¡ ì±„íŒ… ì„œë¹„ìŠ¤
ë©”ì¸ ì±„íŒ… ê¸°ëŠ¥ê³¼ ëŒ€í™” ê´€ë¦¬ (4ê°œ ëª¨ë¸ ì§€ì› + ëŒ€í™”í˜• í• ì¼ ì¶”ì¶œ + TTS)
"""

import logging
from typing import List, Dict, Optional
from datetime import datetime

from sonju_ai.utils.openai_client import OpenAIClient
from sonju_ai.config.prompts import get_prompt, validate_model_type
from sonju_ai.core.todo_processor import TodoProcessor

logger = logging.getLogger(__name__)

# âœ… ëª¨ë“  ChatService ì¸ìŠ¤í„´ìŠ¤ê°€ ê³µìœ í•  TodoProcessor (ìœ ì €+ë°© ë‹¨ìœ„ ìƒíƒœ ìœ ì§€)
_SHARED_TODO_PROCESSOR = TodoProcessor()

# ğŸ†• ì„±ê²©(model_type)ë³„ TTS ìŒì„± ë§¤í•‘
# - AiProfile.personality ê°’(friendly/active/pleasant/reliable)ê³¼ í‚¤ë¥¼ ë§ì¶¤
VOICE_MAPPING = {
    "friendly": "sage",
    "active": "coral",
    "pleasant": "nova",
    "reliable": "verse",
}


def resolve_tts_voice(model_type: str) -> str:
    """model_typeì— ë§ëŠ” TTS voice ë°˜í™˜"""
    return VOICE_MAPPING.get(model_type, "nova")


class ChatService:
    """ì†ì£¼í†¡í†¡ ë©”ì¸ ì±„íŒ… ì„œë¹„ìŠ¤ (4ê°œ AI ëª¨ë¸ + ëŒ€í™”í˜• í• ì¼ ì¶”ì¶œ + TTS)"""

    def __init__(
        self,
        ai_name: str = "ì†ì£¼",
        model_type: str = "friendly",
        todo_processor: Optional[TodoProcessor] = None,
    ) -> None:
        # ëª¨ë¸ íƒ€ì… ìœ íš¨ì„± ê²€ì‚¬
        self.model_type = validate_model_type(model_type)
        self.ai_name = ai_name

        self.openai_client = OpenAIClient()
        # ì£¼ì…ë°›ì§€ ì•Šìœ¼ë©´ ì „ì—­ ê³µìœ  ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        self.todo_processor = todo_processor or _SHARED_TODO_PROCESSOR

        logger.info(
            "ì±„íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (AI ì´ë¦„: %s, ëª¨ë¸: %s)",
            self.ai_name,
            self.model_type,
        )

    # ------------------------------------------------------------------
    # public API
    # ------------------------------------------------------------------
    def chat(
        self,
        user_id: str,
        message: str,
        history: List[Dict],
        enable_tts: bool = False,
        chat_list_num: Optional[int] = None,
    ) -> Dict:
        """
        í•œ í„´ì˜ ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ AI ì‘ë‹µ + í• ì¼ ì¶”ì¶œ ê²°ê³¼ë¥¼ í•¨ê»˜ ë°˜í™˜í•œë‹¤.

        ë°˜í™˜ í˜•ì‹ ì˜ˆì‹œ:
        {
            "response": "...",          # AI í…ìŠ¤íŠ¸
            "timestamp": "...",         # ISO ë¬¸ìì—´
            "ai_name": "ì†ì£¼",
            "model_type": "friendly",
            "tts_path": "outputs/tts/..." | None,
            "has_todo": True/False,
            "task": "...",
            "date": "...",
            "time": "...",
            "step": "none|suggest|ask_confirm|ask_date|saved|cancelled",
        }
        """
        if chat_list_num is None:
            chat_list_num = 0

        try:
            # 1) ìš°ì„  TodoProcessorë¡œ ì´ë²ˆ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•´ì„œ
            #    í• ì¼ í”Œë¡œìš° ìƒíƒœë¥¼ ë¨¼ì € í™•ì¸í•œë‹¤.
            todo_result = self.todo_processor.process_message(
                user_input=message,
                user_id=user_id,
                chat_list_num=chat_list_num,
            )

            step = todo_result.get("step", "none")
            has_todo = todo_result.get("has_todo", False)
            todo_resp = (todo_result.get("response") or "").strip()

            # 2) step ì— ë”°ë¼ ë©”ì¸ ì±—ë´‡ í˜¸ì¶œ ì—¬ë¶€ ê²°ì •
            #
            #   - ask_confirm / ask_date / saved / cancelled:
            #       â†’ Todo ê´€ë ¨ ë©˜íŠ¸ë§Œ ì£¼ê³ , ë©”ì¸ ì±—ë´‡ì€ ë¶€ë¥´ì§€ ì•ŠëŠ”ë‹¤.
            #   - suggest:
            #       â†’ ë©”ì¸ ì±—ë´‡ ë‹µë³€ + "í• ì¼ë¡œ ë“±ë¡í•´ ì¤„ê¹Œ?" ë©˜íŠ¸ë¥¼ í•©ì³ì„œ ì „ë‹¬
            #   - none:
            #       â†’ ìˆœìˆ˜ ë©”ì¸ ì±—ë´‡ë§Œ í˜¸ì¶œ
            if step in {"ask_confirm", "ask_date", "saved", "cancelled"} and todo_resp:
                # í• ì¼ í”Œë¡œìš°ìš© ë©˜íŠ¸ë§Œ ì‚¬ìš©
                ai_text = todo_resp
            else:
                # ë©”ì¸ ì±—ë´‡ í˜¸ì¶œ
                main_answer = self._call_main_chat(
                    message=message,
                    history=history,
                )

                if step == "suggest" and todo_resp:
                    # ìƒˆ í• ì¼ í›„ë³´ê°€ ê°ì§€ëœ ê²½ìš° â†’ ë©”ì¸ ë‹µë³€ ë’¤ì— ì œì•ˆ ë¬¸ì¥ ë¶™ì´ê¸°
                    ai_text = f"{main_answer}\n\n{todo_resp}"
                else:
                    ai_text = main_answer

            # 3) í•„ìš” ì‹œ TTS ìƒì„±
            tts_path: Optional[str] = None
            if enable_tts and ai_text:
                try:
                    tts_path = self._generate_tts(ai_text)
                except Exception as e:
                    # TTS ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë‹ˆ ë¡œê¹…ë§Œ í•˜ê³  ë„˜ì–´ê°„ë‹¤.
                    logger.exception(f"[ChatService] TTS ìƒì„± ì‹¤íŒ¨: {e}")

            # 4) ìµœì¢… ê²°ê³¼ ë¬¶ì–´ì„œ ë°˜í™˜
            return {
                "response": ai_text,
                "timestamp": datetime.now().isoformat(),
                "ai_name": self.ai_name,
                "model_type": self.model_type,
                "tts_path": tts_path,
                "has_todo": has_todo,
                "task": todo_result.get("task"),
                "date": todo_result.get("date"),
                "time": todo_result.get("time"),
                "step": step,
            }

        except Exception as e:
            logger.error(f"[ChatService] chat ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ - user_id={user_id}, err={e}")
            error_response = (
                "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìƒê²¨ì„œ ë‹µë³€ì„ ì™„ì „íˆ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆì–´ìš”. "
                "ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
            )

            return {
                "response": error_response,
                "timestamp": datetime.now().isoformat(),
                "ai_name": self.ai_name,
                "model_type": self.model_type,
                "tts_path": None,
                "has_todo": False,
                "task": None,
                "date": None,
                "time": None,
                "step": "none",
            }

    # ------------------------------------------------------------------
    # ë‚´ë¶€ LLM í˜¸ì¶œ ë° TTS
    # ------------------------------------------------------------------
    def _call_main_chat(
        self,
        message: str,
        history: List[Dict],
    ) -> str:
        """
        ì‹¤ì œ ë©”ì¸ ì±—ë´‡(ì¼ìƒëŒ€í™”/ê²©ë ¤ ë“±) LLMì„ í˜¸ì¶œí•˜ëŠ” ë¶€ë¶„.

        - get_prompt("chat", model_type=..., ai_name=...) í˜•íƒœë¡œ
          ê¸°ì¡´ prompts.py ì˜ íƒ€ì…ì— ë§ì¶° í˜¸ì¶œí•œë‹¤.
        """
        system_prompt = get_prompt(
            "chat",  # âœ… ì—¬ê¸° ì²« ë²ˆì§¸ ì¸ìê°€ prompt_type
            model_type=self.model_type,
            ai_name=self.ai_name,
        )

        messages: List[Dict[str, str]] = [
            {"role": "system", "content": system_prompt},
        ]
        if history:
            messages.extend(history)
        messages.append({"role": "user", "content": message})

        answer = self.openai_client.chat_completion(messages)
        return answer

    def _generate_tts(self, text: str) -> Optional[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì €ì¥ëœ ê²½ë¡œë¥¼ ë°˜í™˜í•œë‹¤.
        OpenAIClient.text_to_speech(...) ì‚¬ìš©.
        """
        voice = resolve_tts_voice(self.model_type)
        return self.openai_client.text_to_speech(text, voice=voice)
